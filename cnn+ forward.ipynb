{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20673cd-3a00-42d2-b3d5-ebfb7a7e36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, random, math, csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os, csv, math, argparse, random\n",
    "from typing import Tuple\n",
    "from torchvision.models import resnet18\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "# -------------------------\n",
    "#  Utils: seed & split\n",
    "# -------------------------\n",
    "def set_seed(seed: int = 20251013):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def stratified_split(y, val_ratio=0.2, seed=20251013):\n",
    "    \"\"\"stratified split on noisy labels y (1D numpy array)\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y)\n",
    "    idx = np.arange(len(y))\n",
    "    tr_idx, val_idx = [], []\n",
    "    for c in np.unique(y):\n",
    "        c_idx = idx[y == c]\n",
    "        rng.shuffle(c_idx)\n",
    "        n_val = int(round(len(c_idx) * val_ratio))\n",
    "        val_idx.append(c_idx[:n_val])\n",
    "        tr_idx.append(c_idx[n_val:])\n",
    "    return np.concatenate(tr_idx), np.concatenate(val_idx)\n",
    "\n",
    "# -------------------------\n",
    "#  Data helpers\n",
    "# -------------------------\n",
    "def infer_image_shape(x2d: np.ndarray) -> Tuple[int,int,int]:\n",
    "    \"\"\"Infer C,H,W from flattened vectors.\"\"\"\n",
    "    D = x2d.shape[1]\n",
    "    if D == 28*28: return (1, 28, 28)\n",
    "    if D == 32*32*3: return (3, 32, 32)\n",
    "    # try square-ish gray\n",
    "    s = int(round(math.sqrt(D)))\n",
    "    if s*s == D: return (1, s, s)\n",
    "    # fallback: 1xHxW where W=D\n",
    "    return (1, 1, D)\n",
    "\n",
    "def to_tensor_images(x: np.ndarray) -> torch.Tensor:\n",
    "    x = x.astype(np.float32)\n",
    "    # scale to [0,1] if looks like 0-255\n",
    "    if x.max() > 1.5: x = x/255.0\n",
    "    if x.ndim == 2:   # flattened\n",
    "        C,H,W = infer_image_shape(x)\n",
    "        x = x.reshape((-1, C, H, W))\n",
    "    elif x.ndim == 3: # (N,H,W) -> (N,1,H,W)\n",
    "        x = x[:, None, ...]\n",
    "    elif x.ndim == 4: # (N,H,W,C) -> (N,C,H,W)\n",
    "        if x.shape[-1] in (1,3):\n",
    "            x = np.transpose(x, (0,3,1,2))\n",
    "    return torch.from_numpy(x)\n",
    "\n",
    "\n",
    "\n",
    "def _normalize_inplace(x: torch.Tensor):\n",
    "    # x: (N,C,H,W) in [0,1]\n",
    "    C, H, W = x.shape[1], x.shape[2], x.shape[3]\n",
    "    # CIFAR-10: 3×32×32\n",
    "    if C == 3 and H == 32 and W == 32:\n",
    "        mean = torch.tensor([0.4914, 0.4822, 0.4465], dtype=x.dtype, device=x.device)[:, None, None]\n",
    "        std  = torch.tensor([0.2023, 0.1994, 0.2010], dtype=x.dtype, device=x.device)[:, None, None]\n",
    "        x.sub_(mean).div_(std)\n",
    "\n",
    "    elif C == 1 and H == 28 and W == 28:\n",
    "        mean = 0.2860\n",
    "        std  = 0.3530\n",
    "        x.sub_(mean).div_(std)\n",
    "   \n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class NumpyTensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, aug: bool=False):\n",
    "        self.X = to_tensor_images(X)\n",
    "        with torch.no_grad():\n",
    "            self.X = _normalize_inplace(self.X)\n",
    "        self.y = torch.from_numpy(y.astype(np.int64))\n",
    "        self.aug = aug\n",
    "\n",
    "    def __len__(self): \n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.X[i], self.y[i]\n",
    "        if self.aug:\n",
    "            # 仅对 CIFAR-10 这种 3×32×32 做增强\n",
    "            if x.shape[0] == 3 and x.shape[-1] == 32 and x.shape[-2] == 32:\n",
    "                # RandomHorizontalFlip\n",
    "                if random.random() < 0.5:\n",
    "                    x = torch.flip(x, dims=[2])  # w 维度翻转（C,H,W），注意 dims=[2]\n",
    "                # RandomCrop(32, padding=4)\n",
    "                pad = 4\n",
    "                x = F.pad(x, (pad, pad, pad, pad), mode='reflect')\n",
    "                i0 = random.randint(0, 2*pad)\n",
    "                j0 = random.randint(0, 2*pad)\n",
    "                x = x[:, j0:j0+32, i0:i0+32]\n",
    "        return x, y\n",
    "\n",
    "# -------------------------\n",
    "#  Models\n",
    "# -------------------------\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 32, 3, padding=1), nn.ReLU(True), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),    nn.ReLU(True), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),   nn.ReLU(True),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.net(x).flatten(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "def make_resnet18_cifar(in_ch: int, num_classes: int):\n",
    "    m = resnet18(weights=None)\n",
    "    m.conv1  = nn.Conv2d(in_ch, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.maxpool = nn.Identity()\n",
    "    m.fc = nn.Linear(512, num_classes)\n",
    "    return m\n",
    "\n",
    "# -------------------------\n",
    "#  Losses (Forward correction)\n",
    "# -------------------------\n",
    "def row_normalize(T: torch.Tensor) -> torch.Tensor:\n",
    "    return T / (T.sum(dim=1, keepdim=True) + 1e-12)\n",
    "\n",
    "def forward_ce_loss(logits, y_noisy, T):\n",
    "    probs = torch.softmax(logits, dim=1)   # [N,K]\n",
    "    noisy_probs = probs @ T                # T: clean->noisy\n",
    "    log_noisy = torch.log(noisy_probs + 1e-12)\n",
    "    return F.nll_loss(log_noisy, y_noisy)\n",
    "# -------------------------\n",
    "#  Anchor-based T estimation\n",
    "# -------------------------\n",
    "@torch.no_grad()\n",
    "def estimate_T_anchor(model, loader, num_classes, device, topk=0.02, min_prob=0.0):\n",
    "    \"\"\"Use validation set (noisy labels) to estimate T_hat.\n",
    "       For each predicted clean class i, take high-confidence samples, tally observed noisy labels.\"\"\"\n",
    "    model.eval()\n",
    "    probs_all, pred_all, noisy_all = [], [], []\n",
    "    for x, s in loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1).cpu()\n",
    "        probs_all.append(probs)\n",
    "        pred_all.append(probs.argmax(1))\n",
    "        noisy_all.append(s)\n",
    "    probs = torch.cat(probs_all)     # [N,K]\n",
    "    preds = torch.cat(pred_all)      # [N]\n",
    "    noisy = torch.cat(noisy_all)     # [N]\n",
    "    T = torch.zeros((num_classes, num_classes), dtype=torch.float64)\n",
    "    N = probs.size(0)\n",
    "    for i in range(num_classes):\n",
    "        idx = (preds == i).nonzero(as_tuple=False).squeeze(1)\n",
    "        if idx.numel() == 0:\n",
    "            T[i] = torch.full((num_classes,), 1.0/num_classes, dtype=torch.float64)\n",
    "            continue\n",
    "\n",
    "        if min_prob > 0.0:\n",
    "            keep = idx[probs[idx, i] >= min_prob]\n",
    "        else:\n",
    "            keep = torch.empty(0, dtype=torch.long)\n",
    "        use = keep\n",
    "        if use.numel() == 0:\n",
    "            k = max(1, int(math.ceil(idx.numel()*topk)))\n",
    "            order = probs[idx, i].argsort(descending=True)\n",
    "            use = idx[order[:k]]\n",
    "        hist = torch.bincount(noisy[use], minlength=num_classes).double()\n",
    "        T[i] = hist / hist.sum().clamp_min(1.0)\n",
    "    return T.float()\n",
    "\n",
    "# -------------------------\n",
    "#  Metrics: Acc, Macro-F1, NLL, ECE\n",
    "# -------------------------\n",
    "def macro_f1_from_preds(y_true: np.ndarray, y_pred: np.ndarray, K: int) -> float:\n",
    "    cm = np.zeros((K, K), dtype=np.int64)\n",
    "    for t, p in zip(y_true, y_pred): cm[t, p] += 1\n",
    "    f1s = []\n",
    "    for k in range(K):\n",
    "        tp = cm[k,k]; fp = cm[:,k].sum()-tp; fn = cm[k,:].sum()-tp\n",
    "        prec = tp / (tp+fp+1e-12); reca = tp / (tp+fn+1e-12)\n",
    "        f1s.append(2*prec*reca/(prec+reca+1e-12))\n",
    "    return float(np.mean(f1s))\n",
    "\n",
    "def ece_score(probs: np.ndarray, y_true: np.ndarray, n_bins: int = 15) -> float:\n",
    "    conf = probs.max(1)\n",
    "    pred = probs.argmax(1)\n",
    "    bins = np.linspace(0.,1.,n_bins+1)\n",
    "    ece = 0.0; N = len(y_true)\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i+1]\n",
    "        m = (conf > lo) & (conf <= hi)\n",
    "        if not np.any(m): continue\n",
    "        acc_b = (pred[m] == y_true[m]).mean()\n",
    "        conf_b = conf[m].mean()\n",
    "        ece += (m.mean())*abs(acc_b - conf_b)\n",
    "    return float(ece)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, num_classes, device):\n",
    "    model.eval()\n",
    "    tot, correct, nll_sum = 0, 0, 0.0\n",
    "    probs_all, y_all, p_all = [], [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        nll_sum += F.nll_loss(torch.log(probs+1e-12), y, reduction='sum').item()\n",
    "        pred = probs.argmax(1)\n",
    "        correct += (pred==y).sum().item()\n",
    "        tot += y.size(0)\n",
    "        probs_all.append(probs.cpu()); y_all.append(y.cpu()); p_all.append(pred.cpu())\n",
    "    probs = torch.cat(probs_all).numpy()\n",
    "    y_true = torch.cat(y_all).numpy()\n",
    "    y_pred = torch.cat(p_all).numpy()\n",
    "    acc = correct / tot\n",
    "    nll = nll_sum / tot\n",
    "    macro_f1 = macro_f1_from_preds(y_true, y_pred, num_classes)\n",
    "    ece = ece_score(probs, y_true, n_bins=15)\n",
    "    return dict(acc=float(acc), macro_f1=float(macro_f1), nll=float(nll), ece=float(ece))\n",
    "\n",
    "# -------------------------\n",
    "#  Train loop (warm-up -> estimate T -> forward training)\n",
    "# -------------------------\n",
    "def train_one(dataset_name, Xtr, Str, Xval, Sval, Xte, Yte, T_given, C,\n",
    "              epochs=50, batch_size=128, lr=1e-3, weight_decay=1e-4,\n",
    "              warmup_epochs=8, topk=0.02, min_prob=0.0, mixT=0.0,\n",
    "              seed=20251013, device='cpu', arch='cnn'):\n",
    "\n",
    "    set_seed(seed)\n",
    "    num_classes = int(C)\n",
    "\n",
    "    train_ds = NumpyTensorDataset(Xtr,Str,aug=True)  \n",
    "    val_ds   = NumpyTensorDataset(Xval,Sval,aug=False)\n",
    "    test_ds  = NumpyTensorDataset(Xte,Yte,aug=False)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = torch.utils.data.DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    in_ch = train_ds.X.shape[1]\n",
    "    use_resnet = (arch == 'resnet18') or (arch == 'auto' and in_ch == 3)\n",
    "\n",
    "\n",
    "    print(\"[DEBUG] use_resnet =\", use_resnet, \"| arch passed =\", arch)\n",
    "\n",
    "    if use_resnet:\n",
    "        m = resnet18(weights=None)\n",
    "        m.conv1  = nn.Conv2d(in_ch, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        m.maxpool = nn.Identity()\n",
    "        m.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        model = m.to(device)\n",
    "        opt = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "    else:\n",
    "        model = SmallCNN(in_ch=in_ch, num_classes=num_classes).to(device)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    T_used = None\n",
    "    if (T_given is not None) and (warmup_epochs == 0):\n",
    "        T_used = row_normalize(T_given.clone().to(device))\n",
    "\n",
    "    for ep in tqdm(range(epochs), desc=f'Training (Seed {seed})', unit=\"epoch\", leave=False):\n",
    "        model.train()\n",
    "        for x, y_noisy in train_loader:\n",
    "            x, y_noisy = x.to(device), y_noisy.to(device)\n",
    "            logits = model(x)\n",
    "            if (T_used is None) or (ep < warmup_epochs):\n",
    "                loss = F.cross_entropy(logits, y_noisy)\n",
    "            else:\n",
    "                loss = forward_ce_loss(logits, y_noisy, T_used) # forward correction\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "        # Switch to Forward: After the warmup ends, the first time\n",
    "        if (ep+1) == warmup_epochs:\n",
    "            if T_given is not None:\n",
    "                T_used = row_normalize(T_given.clone().to(device))\n",
    "            else:\n",
    "                T_hat = estimate_T_anchor(model, val_loader, num_classes, device, topk=topk, min_prob=min_prob)\n",
    "                T_hat = row_normalize(T_hat.to(device))\n",
    "                if mixT > 0.0:\n",
    "                    I = torch.eye(num_classes, device=device)\n",
    "                    T_hat = row_normalize((1.0 - mixT)*T_hat + mixT*I)\n",
    "                T_used = T_hat\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    # Evaluation (clean test labels)\n",
    "    metrics = evaluate(model, test_loader, num_classes, device)\n",
    "    return metrics, (T_used.detach().cpu().numpy() if T_used is not None else None)\n",
    "\n",
    "# -------------------------\n",
    "#  NPZ loader & key guessing\n",
    "# -------------------------\n",
    "def load_npz_dataset(path: str):\n",
    "    d = np.load(path, allow_pickle=True)\n",
    "    keys_all = list(d.keys())\n",
    "\n",
    "    def pick(*cands):\n",
    "        for k in cands:\n",
    "            if k in d:\n",
    "                return k\n",
    "        raise KeyError(f\"Missing any of {cands} in file. Found keys={keys_all}\")\n",
    "\n",
    "    k_Xtr = pick('Xtr','X_train','Xtrain','X_tr')\n",
    "    k_Str = pick('Str','ytr','S','y_train','Ytr','Y_tr')\n",
    "    k_Xte = pick('Xte','Xts','X_test','Xtest','X_te','X_ts')\n",
    "    k_Yte = pick('Yte','Yts','yte','Y_test','Ytest','Y_te','Y_ts')\n",
    "    k_T   = 'T' if 'T' in d else None\n",
    "\n",
    "    Xtr, Str = d[k_Xtr], d[k_Str]\n",
    "    Xte, Yte = d[k_Xte], d[k_Yte]\n",
    "    T = d[k_T].astype(np.float32) if k_T else None\n",
    "    C = int(max(Str.max(), Yte.max()) + 1)\n",
    "\n",
    "    print(f\"[keys] {keys_all}\")\n",
    "    print(f\"[mapping] Xtr={k_Xtr}, Str={k_Str}, Xte={k_Xte}, Yte={k_Yte}, T={'T' if k_T else 'None'}\")\n",
    "    return Xtr, Str, Xte, Yte, T, C\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685477b7-2214-4d4d-95c4-6a77bfab2c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[keys] ['Xtr', 'Str', 'Xte', 'Yte', 'T']\n",
      "[mapping] Xtr=Xtr, Str=Str, Xte=Xte, Yte=Yte, T=T\n",
      "\n",
      "--- Starting Run 1/10 (Seed: 20251013) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6429d39ba3482fb65e3bacbe69b28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251013):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10: acc=0.9887, macroF1=0.9886, NLL=0.0348, ECE=0.0044\n",
      "\n",
      "--- Starting Run 2/10 (Seed: 20251014) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5401bfa24e5b4f20831add32bcd2de5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251014):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10: acc=0.9890, macroF1=0.9890, NLL=0.0275, ECE=0.0045\n",
      "\n",
      "--- Starting Run 3/10 (Seed: 20251015) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf09a315804848b893ba8eb2101d8ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251015):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10: acc=0.9880, macroF1=0.9880, NLL=0.0314, ECE=0.0045\n",
      "\n",
      "--- Starting Run 4/10 (Seed: 20251016) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d54a406b564853a700c5c04aa267fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251016):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10: acc=0.9897, macroF1=0.9897, NLL=0.0341, ECE=0.0071\n",
      "\n",
      "--- Starting Run 5/10 (Seed: 20251017) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ff8f24799243b5ab929618522c8620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251017):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10: acc=0.9887, macroF1=0.9887, NLL=0.0322, ECE=0.0029\n",
      "\n",
      "--- Starting Run 6/10 (Seed: 20251018) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e448f6b854994a43ba33e93f11fac3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251018):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10: acc=0.9893, macroF1=0.9893, NLL=0.0276, ECE=0.0039\n",
      "\n",
      "--- Starting Run 7/10 (Seed: 20251019) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9907916911f462fa9e65fae31d01a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251019):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10: acc=0.9837, macroF1=0.9837, NLL=0.0473, ECE=0.0050\n",
      "\n",
      "--- Starting Run 8/10 (Seed: 20251020) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b7c97d498b4306ba0b6bcfea7c0429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251020):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10: acc=0.9873, macroF1=0.9873, NLL=0.0416, ECE=0.0045\n",
      "\n",
      "--- Starting Run 9/10 (Seed: 20251021) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0284e5278a14538b61973bf0ccaacbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251021):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10: acc=0.9867, macroF1=0.9867, NLL=0.0319, ECE=0.0049\n",
      "\n",
      "--- Starting Run 10/10 (Seed: 20251022) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546b0dc574464b019b6cce31aac20401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251022):   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10: acc=0.9897, macroF1=0.9897, NLL=0.0308, ECE=0.0095\n",
      "\n",
      "==============================\n",
      "==> [FashionMNIST0.3.withT]  acc  = 0.9881 ± 0.0017\n",
      "==> [FashionMNIST0.3.withT]  F1   = 0.9881\n",
      "==> [FashionMNIST0.3.withT]  NLL  = 0.0339\n",
      "==> [FashionMNIST0.3.withT]  ECE  = 0.0051\n",
      "==>  Results saved to: results\\FashionMNIST0.3.withT_forward_runs.csv\n",
      "==============================\n",
      "==> T matrices saved to: results\\FashionMNIST0.3.withT_T_used_runs.npz\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "#  Configuration\n",
    "# -------------------------\n",
    "class Config:\n",
    "    data = 'FashionMNIST0.3.withT.npz'  \n",
    "    arch = 'cnn'                                  \n",
    "    runs = 10\n",
    "    epochs = 50          \n",
    "    warmup_epochs = 0   \n",
    "    topk = 0.02\n",
    "    min_prob = 0.0\n",
    "    mixT = 0.0\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    batch_size = 256\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    val_ratio = 0.2      \n",
    "    seed = 20251013\n",
    "\n",
    "args = Config()\n",
    "\n",
    "# -------------------------\n",
    "#  Main Logic (from main())\n",
    "# -------------------------\n",
    "\n",
    "Xtr, Str, Xte, Yte, T, C = load_npz_dataset(args.data)\n",
    "dataset_name = os.path.splitext(os.path.basename(args.data))[0]\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "out_csv = os.path.join('results', f'{dataset_name}_forward_runs.csv')\n",
    "out_Tnpz = os.path.join('results', f'{dataset_name}_T_used_runs.npz')\n",
    "\n",
    "# CSV header\n",
    "with open(out_csv, 'w', newline='') as f:\n",
    "    csv.writer(f).writerow(['run', 'acc', 'macro_f1', 'nll', 'ece'])\n",
    "\n",
    "all_metrics = []\n",
    "T_collection = {}\n",
    "\n",
    "for r in range(args.runs):\n",
    "    seed = args.seed + r\n",
    "    print(f\"\\n--- Starting Run {r+1}/{args.runs} (Seed: {seed}) ---\")\n",
    "\n",
    "    # stratified split on noisy labels\n",
    "    tr_idx, val_idx = stratified_split(Str, val_ratio=args.val_ratio, seed=seed)\n",
    "    X_tr, S_tr = Xtr[tr_idx], Str[tr_idx]\n",
    "    X_val, S_val = Xtr[val_idx], Str[val_idx]\n",
    "\n",
    "    metrics, T_used = train_one(\n",
    "        dataset_name, X_tr, S_tr, X_val, S_val, Xte, Yte,\n",
    "        None if T is None else torch.from_numpy(T),\n",
    "        C=C,\n",
    "        epochs=args.epochs, batch_size=args.batch_size,\n",
    "        lr=args.lr, weight_decay=args.weight_decay,\n",
    "        warmup_epochs=args.warmup_epochs, topk=args.topk,\n",
    "        min_prob=args.min_prob, mixT=args.mixT,\n",
    "        seed=seed, device=device,\n",
    "        arch=args.arch\n",
    "    )\n",
    "\n",
    "    all_metrics.append(metrics)\n",
    "    with open(out_csv, 'a', newline='') as f:\n",
    "        csv.writer(f).writerow([r+1, metrics['acc'], metrics['macro_f1'], metrics['nll'], metrics['ece']])\n",
    "    print(f\"Run {r+1}/{args.runs}: acc={metrics['acc']:.4f}, macroF1={metrics['macro_f1']:.4f}, \"\n",
    "          f\"NLL={metrics['nll']:.4f}, ECE={metrics['ece']:.4f}\")\n",
    "\n",
    "    if T_used is not None:\n",
    "        T_collection[f'T_run{r+1}'] = T_used\n",
    "\n",
    "\n",
    "accs  = np.array([m['acc'] for m in all_metrics], dtype=np.float64)\n",
    "f1s   = np.array([m['macro_f1'] for m in all_metrics], dtype=np.float64)\n",
    "nlls  = np.array([m['nll'] for m in all_metrics], dtype=np.float64)\n",
    "eces  = np.array([m['ece'] for m in all_metrics], dtype=np.float64)\n",
    "\n",
    "mean_acc, std_acc = accs.mean(), accs.std()\n",
    "mean_f1,  std_f1  = f1s.mean(),  f1s.std()\n",
    "mean_nll, std_nll = nlls.mean(), nlls.std()\n",
    "mean_ece, std_ece = eces.mean(), eces.std()\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"==> [{dataset_name}]  acc  = {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "print(f\"==> [{dataset_name}]  F1   = {mean_f1:.4f}\")\n",
    "print(f\"==> [{dataset_name}]  NLL  = {mean_nll:.4f}\")\n",
    "print(f\"==> [{dataset_name}]  ECE  = {mean_ece:.4f}\")\n",
    "print(f\"==>  Results saved to: {out_csv}\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "with open(out_csv, 'a', newline='') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(['---', '---', '---', '---', '---'])\n",
    "    w.writerow(['mean', mean_acc, mean_f1, mean_nll, mean_ece])\n",
    "    w.writerow(['std',  std_acc,  std_f1,  std_nll,  std_ece])\n",
    "\n",
    "if len(T_collection):\n",
    "    np.savez(out_Tnpz, **T_collection)\n",
    "    print(f\"==> T matrices saved to: {out_Tnpz}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a092777-8f41-492f-b73e-1bcd40304e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[keys] ['Xtr', 'Str', 'Xte', 'Yte', 'T']\n",
      "[mapping] Xtr=Xtr, Str=Str, Xte=Xte, Yte=Yte, T=T\n",
      "\n",
      "--- Starting Run 1/10 (Seed: 20251013) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea4501c4fe4469c8a42dd09fb0d0da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251013):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10: acc=0.9390, macroF1=0.9391, NLL=0.2299, ECE=0.0754\n",
      "\n",
      "--- Starting Run 2/10 (Seed: 20251014) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a41966d43294a3dbfdedd693296f1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251014):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10: acc=0.9187, macroF1=0.9183, NLL=0.2761, ECE=0.0587\n",
      "\n",
      "--- Starting Run 3/10 (Seed: 20251015) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e7aa6ef97c4f5d848fc3fea8f0082d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251015):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10: acc=0.9547, macroF1=0.9545, NLL=0.1910, ECE=0.0723\n",
      "\n",
      "--- Starting Run 4/10 (Seed: 20251016) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8847c29c254404b9806d7cfd312509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251016):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10: acc=0.8930, macroF1=0.8922, NLL=0.3033, ECE=0.0556\n",
      "\n",
      "--- Starting Run 5/10 (Seed: 20251017) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4e3f8f7ac043a4854fc3aefb0bfd49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251017):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10: acc=0.9343, macroF1=0.9344, NLL=0.2278, ECE=0.0441\n",
      "\n",
      "--- Starting Run 6/10 (Seed: 20251018) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d16fdd6e48403a8e8d1a41677ace0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251018):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10: acc=0.7950, macroF1=0.7865, NLL=0.4283, ECE=0.0271\n",
      "\n",
      "--- Starting Run 7/10 (Seed: 20251019) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c729ca648364ab6a6b04f5e77397fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251019):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10: acc=0.9483, macroF1=0.9483, NLL=0.2079, ECE=0.0696\n",
      "\n",
      "--- Starting Run 8/10 (Seed: 20251020) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290e97591fa94a30aed990dae11f33ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251020):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10: acc=0.9473, macroF1=0.9474, NLL=0.2029, ECE=0.0748\n",
      "\n",
      "--- Starting Run 9/10 (Seed: 20251021) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a935537e77545ee99ca449f0da67568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251021):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10: acc=0.9307, macroF1=0.9309, NLL=0.2357, ECE=0.0570\n",
      "\n",
      "--- Starting Run 10/10 (Seed: 20251022) ---\n",
      "[DEBUG] use_resnet = False | arch passed = cnn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a323293f42334a559d91becb2fd26d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251022):   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10: acc=0.9427, macroF1=0.9425, NLL=0.2196, ECE=0.0589\n",
      "\n",
      "==============================\n",
      "==> [FashionMNIST0.6.withT]  acc  = 0.9204 ± 0.0451\n",
      "==> [FashionMNIST0.6.withT]  F1   = 0.9194\n",
      "==> [FashionMNIST0.6.withT]  NLL  = 0.2522\n",
      "==> [FashionMNIST0.6.withT]  ECE  = 0.0593\n",
      "==>  Results saved to: results\\FashionMNIST0.6.withT_forward_runs.csv\n",
      "==============================\n",
      "==> T matrices saved to: results\\FashionMNIST0.6.withT_T_used_runs.npz\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "#  Configuration\n",
    "# -------------------------\n",
    "class Config:\n",
    "\n",
    "    data = 'FashionMNIST0.6.withT.npz'   \n",
    "    arch = 'cnn'                                 \n",
    "    runs = 10\n",
    "    epochs = 60           \n",
    "    warmup_epochs = 0     \n",
    "    topk = 0.02\n",
    "    min_prob = 0.0\n",
    "    mixT = 0.0\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    batch_size = 256\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    val_ratio = 0.2       \n",
    "    seed = 20251013\n",
    "\n",
    "args = Config()\n",
    "\n",
    "# -------------------------\n",
    "#  Main Logic (from main())\n",
    "# -------------------------\n",
    "\n",
    "Xtr, Str, Xte, Yte, T, C = load_npz_dataset(args.data)\n",
    "dataset_name = os.path.splitext(os.path.basename(args.data))[0]\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "out_csv = os.path.join('results', f'{dataset_name}_forward_runs.csv')\n",
    "out_Tnpz = os.path.join('results', f'{dataset_name}_T_used_runs.npz')\n",
    "\n",
    "# CSV header\n",
    "with open(out_csv, 'w', newline='') as f:\n",
    "    csv.writer(f).writerow(['run', 'acc', 'macro_f1', 'nll', 'ece'])\n",
    "\n",
    "all_metrics = []\n",
    "T_collection = {}\n",
    "\n",
    "for r in range(args.runs):\n",
    "    seed = args.seed + r\n",
    "    print(f\"\\n--- Starting Run {r+1}/{args.runs} (Seed: {seed}) ---\")\n",
    "\n",
    "    # stratified split on noisy labels\n",
    "    tr_idx, val_idx = stratified_split(Str, val_ratio=args.val_ratio, seed=seed)\n",
    "    X_tr, S_tr = Xtr[tr_idx], Str[tr_idx]\n",
    "    X_val, S_val = Xtr[val_idx], Str[val_idx]\n",
    "\n",
    "    metrics, T_used = train_one(\n",
    "        dataset_name, X_tr, S_tr, X_val, S_val, Xte, Yte,\n",
    "        None if T is None else torch.from_numpy(T),\n",
    "        C=C,\n",
    "        epochs=args.epochs, batch_size=args.batch_size,\n",
    "        lr=args.lr, weight_decay=args.weight_decay,\n",
    "        warmup_epochs=args.warmup_epochs, topk=args.topk,\n",
    "        min_prob=args.min_prob, mixT=args.mixT,\n",
    "        seed=seed, device=device,\n",
    "        arch=args.arch\n",
    "    )\n",
    "\n",
    "    all_metrics.append(metrics)\n",
    "    with open(out_csv, 'a', newline='') as f:\n",
    "        csv.writer(f).writerow([r+1, metrics['acc'], metrics['macro_f1'], metrics['nll'], metrics['ece']])\n",
    "    print(f\"Run {r+1}/{args.runs}: acc={metrics['acc']:.4f}, macroF1={metrics['macro_f1']:.4f}, \"\n",
    "          f\"NLL={metrics['nll']:.4f}, ECE={metrics['ece']:.4f}\")\n",
    "\n",
    "    if T_used is not None:\n",
    "        T_collection[f'T_run{r+1}'] = T_used\n",
    "\n",
    "\n",
    "accs  = np.array([m['acc'] for m in all_metrics], dtype=np.float64)\n",
    "f1s   = np.array([m['macro_f1'] for m in all_metrics], dtype=np.float64)\n",
    "nlls  = np.array([m['nll'] for m in all_metrics], dtype=np.float64)\n",
    "eces  = np.array([m['ece'] for m in all_metrics], dtype=np.float64)\n",
    "\n",
    "mean_acc, std_acc = accs.mean(), accs.std()\n",
    "mean_f1,  std_f1  = f1s.mean(),  f1s.std()\n",
    "mean_nll, std_nll = nlls.mean(), nlls.std()\n",
    "mean_ece, std_ece = eces.mean(), eces.std()\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"==> [{dataset_name}]  acc  = {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "print(f\"==> [{dataset_name}]  F1   = {mean_f1:.4f}\")\n",
    "print(f\"==> [{dataset_name}]  NLL  = {mean_nll:.4f}\")\n",
    "print(f\"==> [{dataset_name}]  ECE  = {mean_ece:.4f}\")\n",
    "print(f\"==>  Results saved to: {out_csv}\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "with open(out_csv, 'a', newline='') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(['---', '---', '---', '---', '---'])\n",
    "    w.writerow(['mean', mean_acc, mean_f1, mean_nll, mean_ece])\n",
    "    w.writerow(['std',  std_acc,  std_f1,  std_nll,  std_ece])\n",
    "\n",
    "if len(T_collection):\n",
    "    np.savez(out_Tnpz, **T_collection)\n",
    "    print(f\"==> T matrices saved to: {out_Tnpz}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511ad621-8ecd-4a35-868e-4d5fb90cc4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[keys] ['Xtr', 'Str', 'Xts', 'Yts']\n",
      "[mapping] Xtr=Xtr, Str=Str, Xte=Xts, Yte=Yts, T=None\n",
      "\n",
      "--- Starting Run 1/10 (Seed: 20251013) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ac0d3700d24c99b1601ffcf5bd1c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251013):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10: acc=0.2647, macroF1=0.2574, NLL=1.9017, ECE=0.4327\n",
      "\n",
      "--- Starting Run 2/10 (Seed: 20251014) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bf7659e93748b896c0a4dffdb1037e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251014):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10: acc=0.3273, macroF1=0.2653, NLL=2.2627, ECE=0.4243\n",
      "\n",
      "--- Starting Run 3/10 (Seed: 20251015) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abaaeeabfbca46479639c227ba15cc97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251015):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10: acc=0.2867, macroF1=0.3009, NLL=1.9870, ECE=0.4496\n",
      "\n",
      "--- Starting Run 4/10 (Seed: 20251016) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead89ce09cd4478490461bb2347d140f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251016):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10: acc=0.2373, macroF1=0.1563, NLL=3.4563, ECE=0.6390\n",
      "\n",
      "--- Starting Run 5/10 (Seed: 20251017) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d183421500c2458182022b68422f9cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251017):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10: acc=0.2863, macroF1=0.2372, NLL=2.4111, ECE=0.4466\n",
      "\n",
      "--- Starting Run 6/10 (Seed: 20251018) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d656d809835c456a9be2a733cf0e4683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251018):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10: acc=0.4790, macroF1=0.4357, NLL=1.2256, ECE=0.2766\n",
      "\n",
      "--- Starting Run 7/10 (Seed: 20251019) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8889da78e75248119adfdb1dad089922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251019):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10: acc=0.3833, macroF1=0.2974, NLL=2.7204, ECE=0.4737\n",
      "\n",
      "--- Starting Run 8/10 (Seed: 20251020) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3944f274e1284feab1d457b596f89a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251020):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10: acc=0.3727, macroF1=0.3247, NLL=2.1789, ECE=0.3901\n",
      "\n",
      "--- Starting Run 9/10 (Seed: 20251021) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1ccd4fcc4b4a84b5497995b8736fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251021):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10: acc=0.2287, macroF1=0.2355, NLL=2.4019, ECE=0.5377\n",
      "\n",
      "--- Starting Run 10/10 (Seed: 20251022) ---\n",
      "[DEBUG] use_resnet = True | arch passed = resnet18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b0d2f814e54df2bc93cf3dd3db8e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training (Seed 20251022):   0%|          | 0/120 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10: acc=0.4273, macroF1=0.3318, NLL=1.6688, ECE=0.3995\n",
      "\n",
      "==============================\n",
      "==> CIFAR: acc = 0.3293 ± 0.0795\n",
      "==> CIFAR: F1  = 0.2842\n",
      "==> CIFAR: NLL = 2.2214\n",
      "==> CIFAR: ECE = 0.4470\n",
      "==> Results saved to: results\\CIFAR_forward_runs.csv\n",
      "==============================\n",
      "==> T matrices saved to: results\\CIFAR_T_used_runs.npz\n",
      "\n",
      "--- Training complete ---\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "#  Configuration\n",
    "# -------------------------\n",
    "class Config:\n",
    "    data = './datasets/CIFAR.npz'  \n",
    "    arch = 'resnet18'                     \n",
    "    runs = 10                        \n",
    "    epochs = 120                       \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    batch_size = 256\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    seed = 20251013\n",
    "    val_ratio = 0.2\n",
    "    warmup_epochs = 30\n",
    "    topk = 0.01\n",
    "    min_prob = 0.9\n",
    "    mixT = 0.05\n",
    "\n",
    "\n",
    "args = Config()\n",
    "\n",
    "# -------------------------\n",
    "#  Main Logic (from main())\n",
    "# -------------------------\n",
    "\n",
    "Xtr, Str, Xte, Yte, T, C = load_npz_dataset(args.data)\n",
    "dataset_name = os.path.splitext(os.path.basename(args.data))[0]\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "out_csv = os.path.join('results', f'{dataset_name}_forward_runs.csv')\n",
    "out_Tnpz = os.path.join('results', f'{dataset_name}_T_used_runs.npz')\n",
    "\n",
    "# CSV header\n",
    "with open(out_csv, 'w', newline='') as f:\n",
    "    csv.writer(f).writerow(['run', 'acc', 'macro_f1', 'nll', 'ece'])\n",
    "\n",
    "all_metrics = []\n",
    "T_collection = {}\n",
    "\n",
    "for r in range(args.runs):\n",
    "    seed = args.seed + r\n",
    "    print(f\"\\n--- Starting Run {r+1}/{args.runs} (Seed: {seed}) ---\")\n",
    "\n",
    "    # stratified split on noisy labels\n",
    "    tr_idx, val_idx = stratified_split(Str, val_ratio=args.val_ratio, seed=seed)\n",
    "    X_tr, S_tr = Xtr[tr_idx], Str[tr_idx]\n",
    "    X_val, S_val = Xtr[val_idx], Str[val_idx]\n",
    "\n",
    "    metrics, T_used = train_one(\n",
    "        dataset_name, X_tr, S_tr, X_val, S_val, Xte, Yte,\n",
    "        None if T is None else torch.from_numpy(T),\n",
    "        C=C,\n",
    "        epochs=args.epochs, batch_size=args.batch_size,\n",
    "        lr=args.lr, weight_decay=args.weight_decay,\n",
    "        warmup_epochs=args.warmup_epochs, topk=args.topk,\n",
    "        min_prob=args.min_prob, mixT=args.mixT,\n",
    "        seed=seed, device=device,\n",
    "        arch=args.arch\n",
    "    )\n",
    "\n",
    "    all_metrics.append(metrics)\n",
    "    with open(out_csv, 'a', newline='') as f:\n",
    "        csv.writer(f).writerow([r+1, metrics['acc'], metrics['macro_f1'], metrics['nll'], metrics['ece']])\n",
    "    print(f\"Run {r+1}/{args.runs}: acc={metrics['acc']:.4f}, macroF1={metrics['macro_f1']:.4f}, \"\n",
    "          f\"NLL={metrics['nll']:.4f}, ECE={metrics['ece']:.4f}\")\n",
    "\n",
    "    if T_used is not None:\n",
    "        T_collection[f'T_run{r+1}'] = T_used\n",
    "\n",
    "\n",
    "accs  = np.array([m['acc'] for m in all_metrics], dtype=np.float64)\n",
    "f1s   = np.array([m['macro_f1'] for m in all_metrics], dtype=np.float64)\n",
    "nlls  = np.array([m['nll'] for m in all_metrics], dtype=np.float64)\n",
    "eces  = np.array([m['ece'] for m in all_metrics], dtype=np.float64)\n",
    "\n",
    "mean_acc, std_acc = accs.mean(), accs.std()\n",
    "mean_f1,  std_f1  = f1s.mean(),  f1s.std()\n",
    "mean_nll, std_nll = nlls.mean(), nlls.std()\n",
    "mean_ece, std_ece = eces.mean(), eces.std()\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"==> {dataset_name}: acc = {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "print(f\"==> {dataset_name}: F1  = {mean_f1:.4f}\")\n",
    "print(f\"==> {dataset_name}: NLL = {mean_nll:.4f}\")\n",
    "print(f\"==> {dataset_name}: ECE = {mean_ece:.4f}\")\n",
    "print(f\"==> Results saved to: {out_csv}\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "with open(out_csv, 'a', newline='') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(['---', '---', '---', '---', '---'])\n",
    "    w.writerow(['mean', mean_acc, mean_f1, mean_nll, mean_ece])\n",
    "    w.writerow(['std',  std_acc,  std_f1,  std_nll,  std_ece])\n",
    "\n",
    "if len(T_collection):\n",
    "    np.savez(out_Tnpz, **T_collection)\n",
    "    print(f\"==> T matrices saved to: {out_Tnpz}\")\n",
    "\n",
    "print(\"\\n--- Training complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844b9bb-fed0-4c2e-8ac0-d482a9db4416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
