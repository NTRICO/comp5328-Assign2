{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331dd9a7608d7ffc",
   "metadata": {
    "id": "331dd9a7608d7ffc"
   },
   "source": [
    "## Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa725d27b6efd992",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T13:51:51.799802Z",
     "start_time": "2025-10-28T13:51:50.148947Z"
    },
    "id": "fa725d27b6efd992"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from Cython.Compiler.Naming import args_cname\n",
    "from tensorboard.compat.tensorflow_stub.dtypes import float32\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Tuple, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet34\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981d521b3f5319a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T13:21:43.303460Z",
     "start_time": "2025-10-28T13:21:40.781393Z"
    },
    "id": "981d521b3f5319a2"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e114965-4e06-44f2-8150-bcee259dca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.0+cu130\n",
      "CUDA available? True\n",
      "torch.version.cuda: 13.0\n",
      "Device count: 1\n",
      "Device 0: NVIDIA GeForce RTX 5090\n",
      "Python: 3.10.11\n"
     ]
    }
   ],
   "source": [
    "import torch, platform\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available?\", torch.cuda.is_available())\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device 0:\", torch.cuda.get_device_name(0))\n",
    "print(\"Python:\", platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da974a2c67651f",
   "metadata": {
    "id": "13da974a2c67651f"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a04d7f0c76021d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T13:33:39.408058Z",
     "start_time": "2025-10-28T13:33:39.395046Z"
    },
    "id": "4a04d7f0c76021d2"
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_path, val_ratio=0.2, random_state=42):\n",
    "    dataset = np.load(file_path)\n",
    "    Xtr, Str = dataset['Xtr'], dataset['Str']\n",
    "    Xts, Yts = dataset['Xts'], dataset['Yts']\n",
    "\n",
    "    # Shuffle & split (80% train, 20% validation)\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.arange(len(Str))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split_idx = int(len(Str) * (1 - val_ratio))\n",
    "    train_idx, val_idx = indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "    X_train, y_train = Xtr[train_idx], Str[train_idx]\n",
    "    X_val, y_val = Xtr[val_idx], Str[val_idx]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, Xts, Yts\n",
    "\n",
    "def reshape_mnist(*arrays):\n",
    "    reshaped = []\n",
    "\n",
    "    for arr in arrays:\n",
    "        if arr.ndim == 1:\n",
    "            arr = torch.tensor(arr, dtype=torch.long)\n",
    "        elif arr.ndim >= 2:\n",
    "            arr = arr.reshape(-1, 1, 28, 28)\n",
    "            arr = torch.tensor(arr, dtype=torch.float32) / 255.0\n",
    "            mean = torch.tensor(0.1307, dtype=torch.float32).view(1, 1, 1)\n",
    "            std  = torch.tensor(0.3081, dtype=torch.float32).view(1, 1, 1)\n",
    "            arr = (arr - mean) / std\n",
    "        reshaped.append(arr)\n",
    "    return tuple(reshaped)\n",
    "\n",
    "def reshape_cifar(*arrays):\n",
    "    reshaped = []\n",
    "    mean = torch.tensor([0.4914, 0.4822, 0.4465], dtype=torch.float32).view(3, 1, 1)\n",
    "    std  = torch.tensor([0.2023, 0.1994, 0.2010], dtype=torch.float32).view(3, 1, 1)\n",
    "    for arr in arrays:\n",
    "        if arr.ndim == 1:\n",
    "            arr = torch.tensor(arr, dtype=torch.long)\n",
    "        elif arr.ndim >= 2:\n",
    "            arr = np.transpose(arr, (0, 3, 1, 2))\n",
    "            arr = torch.tensor(arr, dtype=torch.float32) / 255.0\n",
    "            arr = (arr - mean) / std\n",
    "        reshaped.append(arr)\n",
    "    return tuple(reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94753f7fe8e2ce2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T13:33:40.217263Z",
     "start_time": "2025-10-28T13:33:40.037515Z"
    },
    "id": "94753f7fe8e2ce2e"
   },
   "outputs": [],
   "source": [
    "Xtr_03, Str_03, Xval_03, Sval_03, Xts_03, Yts_03 = reshape_mnist(*load_dataset('datasets/FashionMNIST0.3.npz'))\n",
    "Xtr_06, Str_06, Xval_06, Sval_06, Xts_06, Yts_06 = reshape_mnist(*load_dataset('datasets/FashionMNIST0.6.npz'))\n",
    "Xtr_cifar, Str_cifar, Xval_cifar, Sval_cifar, Xts_cifar, Yts_cifar = reshape_cifar(*load_dataset('datasets/CIFAR.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd31fa31ebd84f7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T13:33:40.781113Z",
     "start_time": "2025-10-28T13:33:40.768604Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd31fa31ebd84f7d",
    "outputId": "bf84eecf-131b-4bcb-ec4a-5fc05e983d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr_03: torch.Size([14400, 1, 28, 28])\n",
      "Xtr_06: torch.Size([14400, 1, 28, 28])\n",
      "Xtr_cifar: torch.Size([12000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(\"Xtr_03:\", Xtr_03.shape)\n",
    "print(\"Xtr_06:\", Xtr_06.shape)\n",
    "print(\"Xtr_cifar:\", Xtr_cifar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "635db7496d518a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T13:33:41.637497Z",
     "start_time": "2025-10-28T13:33:41.566282Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "635db7496d518a0e",
    "outputId": "fa1f6776-8d6a-4f43-ebf3-bbe8d75ae8fa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mnist data checking\n",
    "plt.imshow(Xtr_03[114, -1, :, :], cmap='gray') #[pic number,_,_,_]\n",
    "plt.title(f\"Label: {Str_03[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9483fb34c05f4089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T13:33:42.777321Z",
     "start_time": "2025-10-28T13:33:42.710432Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "9483fb34c05f4089",
    "outputId": "d10cb08b-9830-466c-e9e0-c70d3c744867"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CIFAR data checking\n",
    "mean_test = torch.tensor([0.4914, 0.4822, 0.4465], dtype=torch.float32).view(3, 1, 1)\n",
    "std_test  = torch.tensor([0.2023, 0.1994, 0.2010], dtype=torch.float32).view(3, 1, 1)\n",
    "test_cifar = Xtr_cifar[514] * std_test + mean_test\n",
    "plt.imshow(np.transpose(test_cifar, (1, -1, 0)))\n",
    "plt.title(f\"Label: {Str_cifar[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e59830c889b5",
   "metadata": {
    "id": "b81e59830c889b5"
   },
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2dc1c0a8571ecb",
   "metadata": {
    "id": "dd2dc1c0a8571ecb"
   },
   "source": [
    "## Classifier: ResNet-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a22e075ea1ad7e",
   "metadata": {
    "id": "e6a22e075ea1ad7e"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes,mode='cifar'):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        if mode == 'cifar':\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        #self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        #self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        #self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64*block.expansion, num_classes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, revision=True):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        #out = self.layer2(out)\n",
    "        #out = self.layer3(out)\n",
    "        #out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = self.linear(out)\n",
    "\n",
    "        clean = F.softmax(out, 1)\n",
    "\n",
    "        return clean\n",
    "\n",
    "def ResNet34(num_classes,mode):\n",
    "  return ResNet(BasicBlock, [1], num_classes,mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3edb74af3457c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:47:55.966800Z",
     "start_time": "2025-10-26T13:47:55.936051Z"
    },
    "id": "7f3edb74af3457c1"
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# transition matrix\n",
    "# ---------------------------\n",
    "class sig_t(nn.Module):\n",
    "    def __init__(self, device, num_classes, init=2):\n",
    "        super(sig_t, self).__init__()\n",
    "\n",
    "        C = num_classes\n",
    "        self.register_parameter(name='w', param=nn.parameter.Parameter(-init*torch.ones(num_classes, num_classes)))\n",
    "\n",
    "        self.w.to(device)\n",
    "        co = torch.full((C, C), 1.0 / (C - 1))\n",
    "        self.co = co.to(device)\n",
    "        self.identity = torch.eye(num_classes).to(device)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        sig = torch.sigmoid(self.w)\n",
    "        T = self.identity.detach() + sig * self.co.detach()\n",
    "        T = F.normalize(T, p=1, dim=1)\n",
    "        return T\n",
    "\n",
    "def logit(p, eps=1e-12):\n",
    "    p = torch.clamp(p, eps, 1 - eps)\n",
    "    return torch.log(p) - torch.log(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d601f0fc872489f",
   "metadata": {
    "id": "9d601f0fc872489f"
   },
   "outputs": [],
   "source": [
    "def warmup(train_data, train_loader, model,optimizer_model, loss_func_ce):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer_model.zero_grad()\n",
    "\n",
    "        clean = model(batch_x)\n",
    "\n",
    "        ce_loss = loss_func_ce(clean.log(), batch_y.long())\n",
    "        res = torch.mean(torch.sum(clean.log() * clean, dim=1))\n",
    "        loss = ce_loss + res\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_model.step()\n",
    "\n",
    "\n",
    "    print('Warmup Loss: {:.6f}'.format(train_loss / (len(train_data))*Cfg.batch_size))\n",
    "\n",
    "\n",
    "def train(train_data, train_loader,model,trans_for,trans_back,optimizer_es,optimizer_trans_for,optimizer_trans_back,scheduler1,scheduler2,scheduler3,loss_func_ce):\n",
    "    model.train()\n",
    "    trans_for.train()\n",
    "    trans_back.train()\n",
    "\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = torch.zeros(batch_x.size(0), Cfg.num_classes).scatter_(1, batch_y.view(-1,1), 1)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        clean = model(batch_x)\n",
    "        noise = F.softmax(batch_y, 1)\n",
    "\n",
    "        t_for = trans_for()\n",
    "        t_back = trans_back()\n",
    "\n",
    "        out = torch.mm(clean, t_for)\n",
    "        out1 = torch.mm(noise, t_back)\n",
    "\n",
    "        noise_y = torch.max(noise, dim=1)[1].detach()\n",
    "        clean_y = torch.max(clean, dim=1)[1].detach()\n",
    "        ce_loss = loss_func_ce(out.log(), noise_y.long())\n",
    "        ce_loss_1 =  loss_func_ce(out1.log(), clean_y.long())\n",
    "\n",
    "        for_back_1 = torch.mm(clean, t_for.detach())\n",
    "        for_back = torch.mm(for_back_1, t_back.detach())\n",
    "\n",
    "        loss_for_back = loss_func_ce(for_back.log(), clean_y.long())  #loss_func_ce(for_back.log(), clean_y.long()) #-torch.mean(torch.sum(for_back.log() * clean,dim=1)) #\n",
    "\n",
    "\n",
    "        loss = ce_loss  + ce_loss_1+ Cfg.lam * loss_for_back\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        train_correct = (pred == noise_y).sum()\n",
    "        train_acc += train_correct.item()\n",
    "\n",
    "        optimizer_es.zero_grad()\n",
    "        optimizer_trans_for.zero_grad()\n",
    "        optimizer_trans_back.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_es.step()\n",
    "        optimizer_trans_for.step()\n",
    "        optimizer_trans_back.step()\n",
    "\n",
    "    print('Train Loss: {:.6f},  Acc: {:.6f}'.format(train_loss / (len(train_data))*Cfg.batch_size,  train_acc / (len(train_data))))\n",
    "\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "    scheduler3.step()\n",
    "\n",
    "\n",
    "def val(val_data, val_loader, model, trans, loss_func_ce):\n",
    "    val_acc = 0.\n",
    "    val_loss = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        trans.eval()\n",
    "\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            clean = model(batch_x)\n",
    "            t = trans()\n",
    "\n",
    "            out = torch.mm(clean, t)\n",
    "            loss = loss_func_ce(out.log(), batch_y.long())\n",
    "            val_loss += loss.item()\n",
    "            pred = torch.max(out, 1)[1]\n",
    "            val_correct = (pred == batch_y).sum()\n",
    "            val_acc += val_correct.item()\n",
    "\n",
    "\n",
    "    print('Val Loss: {:.6f}, Acc: {:.6f}'.format(val_loss / (len(val_data))*Cfg.batch_size, val_acc / (len(val_data))))\n",
    "    return val_loss / (len(val_data))\n",
    "\n",
    "def test(test_data, test_loader, model, loss_func_ce):\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            clean = model(batch_x)\n",
    "\n",
    "            loss = loss_func_ce(clean.log(), batch_y.long())\n",
    "            eval_loss += loss.item()\n",
    "            pred = torch.max(clean, 1)[1]\n",
    "            eval_correct = (pred == batch_y).sum()\n",
    "            eval_acc += eval_correct.item()\n",
    "\n",
    "        print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(test_data)) * Cfg.batch_size,\n",
    "                                                      eval_acc / (len(test_data))))\n",
    "    return eval_acc / (len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dbbdbdfbb271868",
   "metadata": {
    "id": "8dbbdbdfbb271868"
   },
   "outputs": [],
   "source": [
    "def main(dataset_name):\n",
    "\n",
    "      try:\n",
    "          del model\n",
    "      except:\n",
    "          pass\n",
    "      try:\n",
    "          del trans; del trans_1\n",
    "      except:\n",
    "          pass\n",
    "      gc.collect()\n",
    "      if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "      #init\n",
    "      criterion = torch.nn.NLLLoss(reduction=\"mean\")\n",
    "      model = ResNet34(Cfg.num_classes,dataset_name)\n",
    "      milestones = Cfg.milestones\n",
    "\n",
    "      if dataset_name.lower() in (\"mnist03\"):\n",
    "          Xtr, ytr, Xva, yva, Xte, yte = reshape_mnist(*load_dataset(\"datasets/FashionMNIST0.3.npz\"))\n",
    "      elif dataset_name.lower() in (\"mnist06\"):\n",
    "          Xtr, ytr, Xva, yva, Xte, yte = reshape_mnist(*load_dataset(\"datasets/FashionMNIST0.6.npz\"))\n",
    "      elif dataset_name.lower() in (\"cifar\"):\n",
    "          Xtr, ytr, Xva, yva, Xte, yte = reshape_cifar(*load_dataset(\"datasets/CIFAR.npz\"))\n",
    "      else:\n",
    "          raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "      train_data = TensorDataset(Xtr, ytr)\n",
    "      val_data = TensorDataset(Xva, yva)\n",
    "      test_data = TensorDataset(Xte, yte)\n",
    "\n",
    "      trans = sig_t(device, Cfg.num_classes)\n",
    "      trans_1 = sig_t(device, Cfg.num_classes)\n",
    "      optimizer_trans = optim.AdamW(trans.parameters(), lr=Cfg.lr, weight_decay=0)\n",
    "      optimizer_trans_1 = optim.AdamW(trans_1.parameters(), lr=Cfg.lr, weight_decay=0)\n",
    "\n",
    "\n",
    "      #optimizer and StepLR\n",
    "      optimizer_es = optim.AdamW(model.parameters(), lr=Cfg.lr, weight_decay=Cfg.weight_decay)\n",
    "      scheduler1 = MultiStepLR(optimizer_es, milestones=milestones, gamma=0.1)\n",
    "      scheduler2 = MultiStepLR(optimizer_trans, milestones=milestones, gamma=0.1)\n",
    "      scheduler3 = MultiStepLR(optimizer_trans_1, milestones=milestones, gamma=0.1)\n",
    "\n",
    "\n",
    "      #data_loader\n",
    "      train_loader = DataLoader(dataset=train_data,\n",
    "                                batch_size=Cfg.batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=4,\n",
    "                                drop_last=False)\n",
    "\n",
    "      val_loader = DataLoader(dataset=val_data,\n",
    "                              batch_size=Cfg.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=4,\n",
    "                              drop_last=False)\n",
    "\n",
    "      test_loader = DataLoader(dataset=test_data,\n",
    "                              batch_size=Cfg.batch_size,\n",
    "                              num_workers=4,\n",
    "                              drop_last=False)\n",
    "\n",
    "      #cuda\n",
    "      if torch.cuda.is_available:\n",
    "          model = model.to(device)\n",
    "          trans = trans.to(device)\n",
    "          trans_1 = trans_1.to(device)\n",
    "\n",
    "      best_acc = 0\n",
    "      best_acc_back = 0\n",
    "      #warmup\n",
    "      for epoch in range(Cfg.warmup_epoch):\n",
    "          print('epoch[{}], Warmup'.format(epoch + 1))\n",
    "          warmup(train_data, train_loader, model,optimizer_es, criterion)\n",
    "          val(val_data, val_loader, model, trans,criterion)\n",
    "          acc = test(test_data, test_loader, model,criterion)\n",
    "          if acc> best_acc:\n",
    "              best_acc = acc\n",
    "          print('Best_acc: {:.6f}'.format(best_acc))\n",
    "\n",
    "      acc_list = []\n",
    "      early_stop = 0\n",
    "      best_val_acc = -10000\n",
    "\n",
    "      #train\n",
    "      for epoch in range(Cfg.n_epoch):\n",
    "          print('epoch[{}], Train'.format(epoch+1))\n",
    "          train(train_data,train_loader,model,trans,trans_1,optimizer_es,optimizer_trans,optimizer_trans_1,scheduler1,scheduler2,scheduler3,criterion)\n",
    "          val_loss = val(val_data, val_loader, model, trans,criterion)\n",
    "          acc = test(test_data, test_loader, model,criterion)\n",
    "\n",
    "          acc_list.append(acc)\n",
    "\n",
    "\n",
    "          if acc> best_acc and val_loss > best_val_acc:\n",
    "              best_acc = acc\n",
    "              best_val_acc = val_loss\n",
    "              early_stop = 0\n",
    "              print('Best_acc: {:.6f}'.format(best_acc))\n",
    "          else:\n",
    "              early_stop += 1\n",
    "              print('Best_acc: {:.6f}'.format(best_acc))\n",
    "              if early_stop >= Cfg.es_epoch:\n",
    "                print(f\" Early stopping at epoch {epoch+1} (best val_acc={best_acc:.6f})\")\n",
    "                break\n",
    "\n",
    "      with torch.no_grad():\n",
    "        Tf_np = trans().detach().cpu().numpy()\n",
    "        Tb_np = trans_1().detach().cpu().numpy()\n",
    "\n",
    "      print('Best_acc: ', best_acc)\n",
    "      return best_acc,acc_list,Tf_np, Tb_np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KgVDOhM2nJG6",
   "metadata": {
    "id": "KgVDOhM2nJG6"
   },
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbd158abbbbfb37f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T05:55:11.786416Z",
     "start_time": "2025-10-26T05:55:11.770417Z"
    },
    "id": "fbd158abbbbfb37f"
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class Cfg:\n",
    "    num_classes: int = 3\n",
    "    epochs: int = 60\n",
    "    batch_size: int = 128\n",
    "    lr: float = 0.005\n",
    "    momentum: float = 0.9\n",
    "    weight_decay: float = 1e-4\n",
    "    milestones: Tuple[int, int] = (30, 60)\n",
    "    lam: float = 0.6                 # weight for cycle term\n",
    "    n_epoch: int = 120\n",
    "    warmup_epoch: int = 10\n",
    "    es_epoch: int = 10\n",
    "    anchor: bool = False\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2470ffbd9b77e4b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:07:58.556750Z",
     "start_time": "2025-10-26T14:07:58.542750Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2470ffbd9b77e4b0",
    "outputId": "36bd5a6c-b1f3-4424-a8d9-e7e649229d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1], Warmup\n",
      "Warmup Loss: 0.008562\n",
      "Val Loss: 1.132694, Acc: 0.353056\n",
      "Test Loss: 1.098344, Acc: 0.657000\n",
      "Best_acc: 0.657000\n",
      "epoch[2], Warmup\n",
      "Warmup Loss: 0.003345\n",
      "Val Loss: 1.131911, Acc: 0.353056\n",
      "Test Loss: 1.093238, Acc: 0.499667\n",
      "Best_acc: 0.657000\n",
      "epoch[3], Warmup\n",
      "Warmup Loss: 0.001501\n",
      "Val Loss: 1.129710, Acc: 0.370278\n",
      "Test Loss: 1.064023, Acc: 0.840667\n",
      "Best_acc: 0.840667\n",
      "epoch[4], Warmup\n",
      "Warmup Loss: 0.003052\n",
      "Val Loss: 1.133158, Acc: 0.358611\n",
      "Test Loss: 1.057501, Acc: 0.590667\n",
      "Best_acc: 0.840667\n",
      "epoch[5], Warmup\n",
      "Warmup Loss: 0.003746\n",
      "Val Loss: 1.132311, Acc: 0.327778\n",
      "Test Loss: 1.084826, Acc: 0.350333\n",
      "Best_acc: 0.840667\n",
      "epoch[6], Warmup\n",
      "Warmup Loss: 0.001672\n",
      "Val Loss: 1.129552, Acc: 0.361667\n",
      "Test Loss: 1.066706, Acc: 0.561667\n",
      "Best_acc: 0.840667\n",
      "epoch[7], Warmup\n",
      "Warmup Loss: -0.001112\n",
      "Val Loss: 1.130423, Acc: 0.358889\n",
      "Test Loss: 1.048753, Acc: 0.623667\n",
      "Best_acc: 0.840667\n",
      "epoch[8], Warmup\n",
      "Warmup Loss: 0.000078\n",
      "Val Loss: 1.132206, Acc: 0.339444\n",
      "Test Loss: 1.068425, Acc: 0.508667\n",
      "Best_acc: 0.840667\n",
      "epoch[9], Warmup\n",
      "Warmup Loss: 0.001004\n",
      "Val Loss: 1.129265, Acc: 0.380833\n",
      "Test Loss: 1.071688, Acc: 0.843667\n",
      "Best_acc: 0.843667\n",
      "epoch[10], Warmup\n",
      "Warmup Loss: -0.001354\n",
      "Val Loss: 1.130201, Acc: 0.383889\n",
      "Test Loss: 1.068630, Acc: 0.890667\n",
      "Best_acc: 0.890667\n",
      "epoch[1], Train\n",
      "Train Loss: 2.725874,  Acc: 0.329931\n",
      "Val Loss: 1.245680, Acc: 0.327222\n",
      "Test Loss: 1.257275, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      "epoch[2], Train\n",
      "Train Loss: 2.559694,  Acc: 0.329167\n",
      "Val Loss: 1.214121, Acc: 0.327222\n",
      "Test Loss: 1.247127, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      "epoch[3], Train\n",
      "Train Loss: 2.414983,  Acc: 0.329167\n",
      "Val Loss: 1.219521, Acc: 0.327222\n",
      "Test Loss: 1.402488, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      "epoch[4], Train\n",
      "Train Loss: 2.298114,  Acc: 0.329167\n",
      "Val Loss: 1.208256, Acc: 0.327222\n",
      "Test Loss: 1.472570, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      "epoch[5], Train\n",
      "Train Loss: 2.216422,  Acc: 0.329167\n",
      "Val Loss: 1.189904, Acc: 0.327222\n",
      "Test Loss: 1.478625, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      "epoch[6], Train\n",
      "Train Loss: 2.161898,  Acc: 0.329236\n",
      "Val Loss: 1.195812, Acc: 0.327222\n",
      "Test Loss: 1.639188, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      "epoch[7], Train\n",
      "Train Loss: 2.126594,  Acc: 0.329167\n",
      "Val Loss: 1.175941, Acc: 0.327222\n",
      "Test Loss: 1.477778, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      "epoch[8], Train\n",
      "Train Loss: 2.102150,  Acc: 0.329167\n",
      "Val Loss: 1.184786, Acc: 0.327222\n",
      "Test Loss: 1.705924, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      "epoch[9], Train\n",
      "Train Loss: 2.085117,  Acc: 0.329236\n",
      "Val Loss: 1.178935, Acc: 0.326944\n",
      "Test Loss: 1.636712, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      "epoch[10], Train\n",
      "Train Loss: 2.071726,  Acc: 0.329444\n",
      "Val Loss: 1.186125, Acc: 0.327222\n",
      "Test Loss: 1.858072, Acc: 0.333333\n",
      "Best_acc: 0.890667\n",
      " Early stopping at epoch 10 (best val_acc=0.890667)\n",
      "Best_acc:  0.8906666666666667\n"
     ]
    }
   ],
   "source": [
    "best,acc_list, Tf, Tb = main(dataset_name=\"mnist06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab69b8d668a12854",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab69b8d668a12854",
    "outputId": "bf5c801c-8bcd-4d04-9914-b7f1b0c743c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Forward T (cleannoisy) ===\n",
      "[[0.53  0.235 0.235]\n",
      " [0.008 0.943 0.049]\n",
      " [0.007 0.05  0.942]]\n",
      "row sums: [1. 1. 1.]\n",
      "\n",
      "=== Backward T (noisyclean) ===\n",
      "[[0.992 0.004 0.004]\n",
      " [0.308 0.69  0.002]\n",
      " [0.308 0.002 0.69 ]]\n",
      "row sums: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Forward T (cleannoisy) ===\")\n",
    "print(np.array_str(Tf, precision=3, suppress_small=True, max_line_width=180))\n",
    "print(\"row sums:\", np.round(Tf.sum(axis=1), 3))\n",
    "\n",
    "print(\"\\n=== Backward T (noisyclean) ===\")\n",
    "print(np.array_str(Tb, precision=3, suppress_small=True, max_line_width=180))\n",
    "print(\"row sums:\", np.round(Tb.sum(axis=1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489830f2d82f3ce",
   "metadata": {
    "id": "489830f2d82f3ce"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e9782-bcff-4d5c-86fe-5d5089bf42f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683cdf52-18d9-4b12-8e6e-fb9a8f528852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003dc25-b30d-445c-bbc4-48c64ed37e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a761588-c31a-4384-8c0a-5f4bb9f2774e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
