{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Library",
   "id": "331dd9a7608d7ffc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T13:34:26.502326Z",
     "start_time": "2025-10-25T13:34:24.140542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Tuple, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "fa725d27b6efd992",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T13:34:34.291674Z",
     "start_time": "2025-10-25T13:34:34.140636Z"
    }
   },
   "cell_type": "code",
   "source": "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "981d521b3f5319a2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "13da974a2c67651f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T13:34:35.259762Z",
     "start_time": "2025-10-25T13:34:35.245761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dataset(file_path, val_ratio=0.2, random_state=42):\n",
    "    dataset = np.load(file_path)\n",
    "    Xtr, Str = dataset['Xtr'], dataset['Str']\n",
    "    Xts, Yts = dataset['Xts'], dataset['Yts']\n",
    "\n",
    "    # Shuffle & split (80% train, 20% validation)\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.arange(len(Str))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split_idx = int(len(Str) * (1 - val_ratio))\n",
    "    train_idx, val_idx = indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "    X_train, y_train = Xtr[train_idx], Str[train_idx]\n",
    "    X_val, y_val = Xtr[val_idx], Str[val_idx]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, Xts, Yts\n",
    "\n",
    "def reshape_mnist(*arrays):\n",
    "    reshaped = []\n",
    "    for arr in arrays:\n",
    "        if arr.ndim == 1:\n",
    "            arr = torch.tensor(arr, dtype=torch.long)\n",
    "        elif arr.ndim >= 2:\n",
    "            arr = arr.reshape(-1, 1, 28, 28)\n",
    "            arr = torch.tensor(arr, dtype=torch.float32) / 255.0\n",
    "        reshaped.append(arr)\n",
    "    return tuple(reshaped)\n",
    "\n",
    "def reshape_cifar(*arrays):\n",
    "    reshaped = []\n",
    "    for arr in arrays:\n",
    "        if arr.ndim == 1:\n",
    "            arr = torch.tensor(arr, dtype=torch.long)\n",
    "        elif arr.ndim >= 2:\n",
    "            arr = np.transpose(arr, (0, 3, 1, 2))\n",
    "            arr = torch.tensor(arr, dtype=torch.float32) / 255.0\n",
    "        reshaped.append(arr)\n",
    "    return tuple(reshaped)\n"
   ],
   "id": "4a04d7f0c76021d2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T13:34:36.177187Z",
     "start_time": "2025-10-25T13:34:36.018307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Xtr_03, Str_03, Xval_03, Sval_03, Xts_03, Yts_03 = reshape_mnist(*load_dataset('datasets/FashionMNIST0.3.npz'))\n",
    "Xtr_06, Str_06, Xval_06, Sval_06, Xts_06, Yts_06 = reshape_mnist(*load_dataset('datasets/FashionMNIST0.6.npz'))\n",
    "Xtr_cifar, Str_cifar, Xval_cifar, Sval_cifar, Xts_cifar, Yts_cifar = reshape_cifar(*load_dataset('datasets/CIFAR.npz'))"
   ],
   "id": "94753f7fe8e2ce2e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Xtr_03:\", Xtr_03.shape)\n",
    "print(\"Xtr_06:\", Xtr_06.shape)\n",
    "print(\"Xtr_cifar:\", Xtr_cifar.shape)\n"
   ],
   "id": "cd31fa31ebd84f7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Mnist data checking\n",
    "plt.imshow(Xtr_03[114, -1, :, :], cmap='gray') #[pic number,_,_,_]\n",
    "plt.title(f\"Label: {Str_03[0]}\")\n",
    "plt.show()"
   ],
   "id": "635db7496d518a0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CIFAR data checking\n",
    "plt.imshow(np.transpose(Xtr_cifar[514], (1, -1, 0)))\n",
    "plt.title(f\"Label: {Str_cifar[0]}\")\n",
    "plt.show()"
   ],
   "id": "9483fb34c05f4089",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4# Main Program",
   "id": "b81e59830c889b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classifier: ResNet-34",
   "id": "dd2dc1c0a8571ecb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T13:34:44.642233Z",
     "start_time": "2025-10-25T13:34:44.631241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class Config:\n",
    "    epochs: int = 60\n",
    "    batch_size: int = 128\n",
    "    lr: float = 1e-2\n",
    "    momentum: float = 0.9\n",
    "    weight_decay: float = 1e-3\n",
    "    milestones: Tuple[int, int] = (30, 60)\n",
    "    lam: float = 0.3                 # weight for cycle term\n",
    "    label_smoothing: float = 0.0\n",
    "    diag_reg_weight: float = 0.0     # >0 to enforce diagonal-dominance\n",
    "    diag_margin: float = 0.05\n",
    "    use_tqdm: bool = True\n",
    "    tqdm_leave: bool = False\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "id": "fbd158abbbbfb37f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T13:34:45.345462Z",
     "start_time": "2025-10-25T13:34:45.332450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# ResNet-34 (classifier-oriented)\n",
    "# ---------------------------\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, in_channels: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(64, 3)\n",
    "        self.layer2 = self._make_layer(128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 3, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1):\n",
    "        layers = [BasicBlock(self.inplanes, planes, stride)]\n",
    "        self.inplanes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x); x = self.layer2(x); x = self.layer3(x); x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n"
   ],
   "id": "34306759164620d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes,mode='cifar10'):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        if mode == 'mnist':\n",
    "            self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, revision=True):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = self.linear(out)\n",
    "\n",
    "        clean = F.softmax(out, 1)\n",
    "\n",
    "        return clean\n",
    "    def ResNet34(num_classes):\n",
    "        return ResNet(BasicBlock, [3,4,6,3], num_classes)\n",
    "'''"
   ],
   "id": "e6a22e075ea1ad7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T13:34:50.328536Z",
     "start_time": "2025-10-25T13:34:50.302408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# Column-stochastic T/T'\n",
    "# ---------------------------\n",
    "class ColumnStochastic(nn.Module):\n",
    "    \"\"\"\n",
    "    Column-stochastic via column-wise softmax. Init near identity to encourage diagonal dominance.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int, init_identity: bool = True):\n",
    "        super().__init__()\n",
    "        logits = torch.zeros(num_classes, num_classes)\n",
    "        if init_identity:\n",
    "            logits += -4.0\n",
    "            for i in range(num_classes):\n",
    "                logits[i, i] = 4.0\n",
    "        self.logits = nn.Parameter(logits)\n",
    "\n",
    "    def forward(self):\n",
    "        return F.softmax(self.logits, dim=0)  # column-wise softmax\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def as_numpy(self):\n",
    "        return self.forward().detach().cpu().numpy()\n",
    "\n",
    "    def diag_dominance_loss(self, margin: float = 0.05):\n",
    "        T = self.forward().detach()\n",
    "        C = T.shape[0]\n",
    "        loss = 0.0\n",
    "        for j in range(C):\n",
    "            diag = T[j, j]\n",
    "            off = torch.cat([T[:j, j], T[j+1:, j]]) if C > 1 else T[j:j+1, j]\n",
    "            max_off = off.max() if off.numel() > 0 else torch.tensor(0.0, device=off.device)\n",
    "            loss += F.relu(max_off - diag + margin)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Utils\n",
    "# ---------------------------\n",
    "def one_hot(idx: torch.Tensor, num_classes: int, smoothing: float = 0.0):\n",
    "    y = F.one_hot(idx, num_classes).float()\n",
    "    return y * (1.0 - smoothing) + smoothing / num_classes if smoothing > 0 else y\n",
    "\n",
    "def ce_soft(pred_probs: torch.Tensor, target_probs: torch.Tensor, eps: float = 1e-12):\n",
    "    pred = torch.clamp(pred_probs, eps, 1.0)\n",
    "    return -(target_probs * pred.log()).sum(dim=1).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def top1_acc(logits: torch.Tensor, y: torch.Tensor):\n",
    "    return (logits.argmax(1) == y).float().mean().item()\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# CCR Trainer (class-based, tqdm)\n",
    "# ---------------------------\n",
    "class CCRTrainer:\n",
    "    \"\"\"\n",
    "    Train single ResNet-34 classifier with CCR losses:\n",
    "      L1 = CE(y~, T @ p_clean)\n",
    "      L2 = CE(p_clean, T' @ y~)\n",
    "      L3 = CE(p_clean, T' @ (T @ p_clean))\n",
    "      Total: L = L1 + L2 + lam * L3\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: Tuple[int, int, int], num_classes: int, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        C_in, _, _ = input_shape\n",
    "        self.device = torch.device(cfg.device)\n",
    "        self.model = ResNet34(C_in, num_classes).to(self.device)\n",
    "        self.T = ColumnStochastic(num_classes, init_identity=True).to(self.device)\n",
    "        self.Tp = ColumnStochastic(num_classes, init_identity=True).to(self.device)\n",
    "\n",
    "        params = list(self.model.parameters()) + list(self.T.parameters()) + list(self.Tp.parameters())\n",
    "        self.opt = torch.optim.SGD(params, lr=cfg.lr, momentum=cfg.momentum, weight_decay=cfg.weight_decay)\n",
    "        self.sched = torch.optim.lr_scheduler.MultiStepLR(self.opt, milestones=list(cfg.milestones), gamma=0.1)\n",
    "\n",
    "    def _train_one_epoch(self, loader: DataLoader, epoch: int) -> float:\n",
    "        self.model.train(); self.T.train(); self.Tp.train()\n",
    "        running = 0.0\n",
    "        iterator = tqdm(loader, desc=f\"Epoch {epoch}/{self.cfg.epochs}\", leave=self.cfg.tqdm_leave) \\\n",
    "                  if self.cfg.use_tqdm else loader\n",
    "\n",
    "        for it, (xb, yb) in enumerate(iterator, start=1):\n",
    "            xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            logits = self.model(xb)\n",
    "            p_clean = F.softmax(logits, dim=1)\n",
    "\n",
    "            T = self.T()\n",
    "            Tp = self.Tp()\n",
    "\n",
    "            # L1: CE(y~, T @ p_clean)\n",
    "            p_noisy = (T @ p_clean.T).T\n",
    "            L1 = F.nll_loss(torch.log(torch.clamp(p_noisy, 1e-12, 1.0)), yb)\n",
    "\n",
    "            # L2: CE(p_clean, T' @ y~)\n",
    "            y_prob = one_hot(yb, p_clean.shape[1], smoothing=self.cfg.label_smoothing)\n",
    "            proj_clean = (Tp @ y_prob.T).T\n",
    "            L2 = ce_soft(p_clean, proj_clean)\n",
    "\n",
    "            # L3: CE(p_clean, T'(T p_clean))\n",
    "            cyc = (Tp @ (T @ p_clean.T)).T\n",
    "            L3 = ce_soft(p_clean, cyc)\n",
    "\n",
    "            loss = L1 + L2 + self.cfg.lam * L3\n",
    "\n",
    "            if self.cfg.diag_reg_weight > 0.0:\n",
    "                loss = loss + self.cfg.diag_reg_weight * (\n",
    "                    self.T.diag_dominance_loss(self.cfg.diag_margin) +\n",
    "                    self.Tp.diag_dominance_loss(self.cfg.diag_margin)\n",
    "                )\n",
    "\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "\n",
    "            running += float(loss.item())\n",
    "            if self.cfg.use_tqdm:\n",
    "                self._set_postfix(iterator, it, running)\n",
    "\n",
    "        return running / max(1, it)\n",
    "\n",
    "    def _set_postfix(self, iterator, it, running):\n",
    "        lr_curr = self.opt.param_groups[0][\"lr\"]\n",
    "        iterator.set_postfix(loss=f\"{running/it:.4f}\", lr=f\"{lr_curr:.3e}\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _eval_loader(self, loader: DataLoader) -> float:\n",
    "        self.model.eval()\n",
    "        accs = []\n",
    "        iterator = tqdm(loader, desc=\"Eval\", leave=self.cfg.tqdm_leave) if self.cfg.use_tqdm else loader\n",
    "        for xb, yb in iterator:\n",
    "            xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "            logits = self.model(xb)\n",
    "            accs.append(top1_acc(logits, yb))\n",
    "        return float(np.mean(accs)) if len(accs) > 0 else 0.0\n",
    "\n",
    "    def fit(self, train_loader: DataLoader, val_loader: DataLoader, test_loader: DataLoader) -> Dict[str, Any]:\n",
    "        best_val, best_test = 0.0, 0.0\n",
    "        for ep in range(1, self.cfg.epochs + 1):\n",
    "            train_loss = self._train_one_epoch(train_loader, ep)\n",
    "            self.sched.step()\n",
    "\n",
    "            val_acc = self._eval_loader(val_loader)\n",
    "            test_acc = self._eval_loader(test_loader)\n",
    "            if val_acc > best_val:\n",
    "                best_val, best_test = val_acc, test_acc\n",
    "\n",
    "            print(f\"Epoch {ep:03d} | train_loss={train_loss:.4f}  val={val_acc*100:.2f}% \"\n",
    "                  f\"test={test_acc*100:.2f}%  best@val={best_test*100:.2f}%\")\n",
    "\n",
    "        return {\n",
    "            \"best_val_acc\": best_val,\n",
    "            \"best_test_acc\": best_test,\n",
    "            \"T\": self.T.as_numpy(),\n",
    "            \"Tp\": self.Tp.as_numpy(),\n",
    "            \"state_dict\": self.model.state_dict()\n",
    "        }"
   ],
   "id": "7f3edb74af3457c1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T13:49:55.147329400Z",
     "start_time": "2025-10-25T13:44:09.458218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =============================================================\n",
    "# 🔬 Quick Test: ONLY use mnist0.3 tensors already loaded above\n",
    "#     (append this block at the very bottom of your file)\n",
    "# =============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    # ---- 0) 绑定 tqdm：兼容你当前的 `import tqdm` 顶部导入写法 ----\n",
    "    try:\n",
    "        # 如果是 `import tqdm`\n",
    "        if hasattr(tqdm, \"tqdm\"):\n",
    "            tqdm = tqdm.tqdm\n",
    "    except NameError:\n",
    "        # 兜底：如果上面没导入成功，就用更智能的 auto 版本\n",
    "        from tqdm.auto import tqdm  # noqa: F401\n",
    "\n",
    "    # ---- 1) 选择 mnist0.3 的“已载入张量作为网络输入” ----\n",
    "    Xtr, Str = Xtr_cifar, Str_cifar\n",
    "    Xva, Sva = Xval_cifar, Sval_cifar\n",
    "    Xte, Yte = Xts_cifar, Yts_cifar\n",
    "\n",
    "    # ---- 2) 基本校验：保证后面训练真的用到你载入的张量 ----\n",
    "\n",
    "\n",
    "    # ---- 3) 构建 DataLoader（仅使用 mnist0.3 这套）----\n",
    "    def make_loader(X, y, bs=128, shuffle=False, num_workers=2):\n",
    "        ds = TensorDataset(X, y)\n",
    "        return DataLoader(ds, batch_size=bs, shuffle=shuffle, pin_memory=True, num_workers=num_workers)\n",
    "\n",
    "    batch_size = 128\n",
    "    train_loader = make_loader(Xtr, Str, bs=batch_size, shuffle=True)\n",
    "    val_loader   = make_loader(Xva, Sva, bs=batch_size)\n",
    "    test_loader  = make_loader(Xte, Yte, bs=batch_size)\n",
    "\n",
    "    # ---- 4) 打印一个 batch，确认网络真实输入的是你载入的张量 ----\n",
    "    xb_chk, yb_chk = next(iter(train_loader))\n",
    "    print(f\"\\nSanity batch -> xb: {tuple(xb_chk.shape)} (min={xb_chk.min():.3f}, max={xb_chk.max():.3f}), \"\n",
    "          f\"yb: {tuple(yb_chk.shape)}, labels in [ {int(yb_chk.min())} , {int(yb_chk.max())} ]\")\n",
    "\n",
    "    # ---- 5) 组装配置，跑一个短训练（冒烟测试），确认流程正确 ----\n",
    "    input_shape = tuple(Xtr.shape[1:])                # (1,28,28)\n",
    "    num_classes = int(Str.max().item()) + 1\n",
    "\n",
    "    cfg = Config(\n",
    "        epochs=60,                 # 先小跑 5 个 epoch 验证流程；确认无误再改回 60\n",
    "        batch_size=batch_size,\n",
    "        lr=1e-2,\n",
    "        momentum=0.9,\n",
    "        weight_decay=1e-3,\n",
    "        milestones=(30, 60),\n",
    "        lam=0.3,\n",
    "        label_smoothing=0.0,\n",
    "        diag_reg_weight=0.0,\n",
    "        diag_margin=0.05,\n",
    "        use_tqdm=True,\n",
    "        tqdm_leave=False,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    )\n",
    "\n",
    "    print(f\"\\n🚀 Start CCR on MNIST0.3 with your loaded tensors \"\n",
    "          f\"(input={input_shape}, classes={num_classes}, device={cfg.device})\")\n",
    "    trainer = CCRTrainer(input_shape, num_classes, cfg)\n",
    "\n",
    "    # ---- 6) 训练并汇报结果（确保输出与你预期格式一致）----\n",
    "    result = trainer.fit(train_loader, val_loader, test_loader)\n",
    "\n"
   ],
   "id": "8dbbdbdfbb271868",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sanity batch -> xb: (128, 3, 32, 32) (min=0.000, max=1.000), yb: (128,), labels in [ 0 , 2 ]\n",
      "\n",
      "🚀 Start CCR on MNIST0.3 with your loaded tensors (input=(3, 32, 32), classes=3, device=cuda)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1/60:   0%|          | 0/94 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7086fc05a1540cba6a8678127f8c015"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afcd0c52b3fc45d1b0c8ccac52ee048d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3347d60cd76d443a8bd7b88edcf831b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=2.8359  val=33.38% test=33.23%  best@val=33.23%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2/60:   0%|          | 0/94 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e540588693da41b4bbf67a5600552e47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "583e3680bf9e415faaba00356ea5deb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c449d30e9dc4facbb35c4ed955ac243"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | train_loss=2.5763  val=35.45% test=34.88%  best@val=34.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3/60:   0%|          | 0/94 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "856e986da2df407fb2b01e98631c577c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b4df2e0dd774a58a707f2bf7b5d1a18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1637ee08058548d6a098785a51bf3847"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | train_loss=2.5341  val=35.44% test=53.12%  best@val=34.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4/60:   0%|          | 0/94 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a228d424a2d148b2a56372731bb500ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9511a4c33e5543b7bbbc4351c798c740"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdcfe29ff7ba425690eba5f7cce62d6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | train_loss=2.5217  val=34.66% test=41.04%  best@val=34.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5/60:   0%|          | 0/94 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36ee531d8ebc4aa0a46c501f318ed155"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2ad5465ee1944259d39b2d064f4f918"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a2dbfe67bd04b9b90a071b0fa76df47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | train_loss=2.5225  val=36.93% test=55.06%  best@val=55.06%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6/60:   0%|          | 0/94 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50c0a90e7c9c4b05a886a7add3faf8d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c33dd62f58074f64bb56aa18c0a06776"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7066ecea02ce4e8cbdd0c87313c35548"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | train_loss=2.5167  val=37.15% test=43.76%  best@val=43.76%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7/60:   0%|          | 0/94 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cc0b023e078480ea113c3dd82adfa7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba6a1902ca0049c7a1ae0c0071e89f5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eval:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "508b08f5017c4e9291290c62be412803"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001FEBB491DC0>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda3\\envs\\my_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"d:\\Anaconda3\\envs\\my_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1627, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"d:\\Anaconda3\\envs\\my_pytorch\\lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"d:\\Anaconda3\\envs\\my_pytorch\\lib\\multiprocessing\\popen_spawn_win32.py\", line 108, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T13:43:53.154294Z",
     "start_time": "2025-10-25T13:43:53.138289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "    print(\"\\n✅ Test (MNIST0.3) complete.\")\n",
    "    print(f\"Best Test Accuracy @ Val = {result['best_test_acc']*100:.2f}%\")\n",
    "\n",
    "    # 可选：检查学到的转移矩阵\n",
    "    T_est, Tp_est = result[\"T\"], result[\"Tp\"]\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    print(\"\\nForward T (shape:\", T_est.shape, \") first 3 cols:\\n\", T_est[:, :min(3, T_est.shape[1])])\n",
    "    print(\"\\nBackward T' (shape:\", Tp_est.shape, \") first 3 cols:\\n\", Tp_est[:, :min(3, Tp_est.shape[1])])"
   ],
   "id": "2470ffbd9b77e4b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test (MNIST0.3) complete.\n",
      "Best Test Accuracy @ Val = 52.94%\n",
      "\n",
      "Forward T (shape: (3, 3) ) first 3 cols:\n",
      " [[0.999  0.0005 0.0005]\n",
      " [0.0005 0.999  0.0005]\n",
      " [0.0005 0.0005 0.999 ]]\n",
      "\n",
      "Backward T' (shape: (3, 3) ) first 3 cols:\n",
      " [[0.999  0.0005 0.0005]\n",
      " [0.0005 0.999  0.0005]\n",
      " [0.0005 0.0005 0.999 ]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "T_est",
   "id": "ab69b8d668a12854",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "489830f2d82f3ce",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
